\documentclass[../notes.tex]{subfiles}

\begin{document}

\section{Graph Mining and Social Network Analysis}

\subsection{Graphs and social networks}

\subsubsection{Basic Definitions}

\begin{itemize}
  \item Graph G = (V, E)
  \begin{itemize}
    \item V: set of vertices / nodes
    \item $E \subseteq V*V$: set of edges
  \end{itemize}

  \item Graph can be directed (asymmetric relationships) or undirected (symmetric relationships)

  \item Adjacency matrix (sociomatrix) alternative representation of a graph
  \begin{itemize}
    \item $y_{i, j} = 
  \begin{cases}
    1, & \text{if} (v_i, v_j) \in E \\
    0,              & \text{otherwise}
  \end{cases}$ 
  \end{itemize}

  \item Network: used as synonym to graph, a more application-oriented term.

  \item Labeled graph
  \begin{itemize}
    \item set of labels $L$ for nodes or edges
    \item $f: V \rightarrow L$ or $f: E \rightarrow L$
    \item $|L|$ typically small
  \end{itemize}

  \item Attribute graph
  \begin{itemize}
    \item set of attributes with domain $D_1, D_2, ..., D_d$
    \item $f: V \rightarrow D_1 * D_2 * ... * D_d$
    \item $|D_i|$ typically large, can have continuous domains
  \end{itemize}

  \item Neighbors $N_i$ of node $v_i$:
  \begin{itemize}
    \item $N_i = \{v_j \in V | (v_i, v_j) \in E \}$    
  \end{itemize}

  \item Degree $deg(v)$ of node $v$: 
  \begin{itemize}
    \item $deg(v) = |N_i|$
  \end{itemize}  

  \item Clustering coefficient of node $v$:
  \begin{itemize}
    \item fraction of pairs of neighbors of $v$ that are connected
  \end{itemize}  

  \item Betweeness of node $v$, or of edge $e$
  \begin{itemize}
    \item number of shortest paths between any pair of nodes in G that go through $v$ or $e$
  \end{itemize}  

  \item Shortest path distance between nodes $v_1$ and $v_2$
  \begin{itemize}
    \item length of shortest path between $v_1$ and $v_2$
    \item also called minimum geodesic distance
  \end{itemize}

  \item Diameter of graph $G$
  \begin{itemize}
    \item maximum shortest path distance for any pair of nodes in $G$
  \end{itemize}

  \item Effective diameter of graph $G$
  \begin{itemize}
    \item distance at which 90\% of all connected pairs of nodes can be reached
  \end{itemize}

  \item Mean geodesic distance of graph $G$
  \begin{itemize}
    \item average minimum geodesic distance for any pair of nodes in $G$
  \end{itemize}

  \newpage
  
  \item Small-world network
  \begin{itemize}
    \item network with ``small'' mean geodesic distance / effective diameter
  \end{itemize}

  \item Scale-free networks
  \begin{itemize}
    \item networks with a power law degree distribution $f(cx) \propto f(x)$
    \item $P(k) = k^{-\lambda}$ where P(k) is the probability that a node has degree $k$ ($\lambda$ typically between 2 and 3)
  \end{itemize}
\end{itemize}

\subsubsection{Graphs and Social Networks}
\textbf{Data Mining Scenarios}
\begin{itemize}
  \item One large graph
  \begin{itemize}
    \item mine dense subgraphs or clusters
    \item analyze evolution
  \end{itemize}

  \item Many small graph
  \begin{itemize}
    \item mine frequent subgraphs
  \end{itemize}

  \item Two collections of many small graphs
  \begin{itemize}
    \item classify graphs
  \end{itemize}

\end{itemize}

\subsection{Graph pattern mining}
\subsubsection{Frequent Pattern Mining}
\begin{itemize}
  \item Given a graph dataset $DB$
  \begin{itemize}
    \item i.e. a set of labeled graphs $G_1, G_2, ..., G_n$ and a minimum support $\theta$, $0 \le \theta \le 1$
  \end{itemize}

  \item Find the graphs that are contained in at least $\theta n$ of the graphs of $DB$
  \item Assumption: the more frequent, the more interesting a graph
  \item $G$ contained in $G_i$:
  \begin{itemize}
    \item $G$ is isomorph to a subgraph of $G_i$
  \end{itemize}
\end{itemize}

\textbf{Anti-Monotonicity Property}
\begin{itemize}
  \item If a graph is frequent, all of its subgraphs are frequent.
  \item Can prune all candidates patterns that have an infrequent subgraph, i.e. disregard them from further consideration
  \item The higher $\theta$, the more effective the pruning.
\end{itemize}

\textbf{Duplicate Elimination}
\begin{itemize}
  \item Given existing patterns $G_1, G_2, ..., G_m$ and newly discovered pattern $G$. Is G a duplicate?
  \item Method 1 (slow)
  \begin{itemize}
    \item Check graph isomorphism of $G$ with each of the $G_i$
    \item Graph isomorphism test is a very expensive operation
  \end{itemize}

  \item Method 2 (faster)
  \begin{itemize}
    \item Transform each graph $G_i$ into a canonical form and hash it into a hash table.
    \item Transform $G$ in the same way and check whether there is already a graph $G_i$ with the same hash value.
    \item Test for graph isomorphism only if such $G_i$ already exists.
  \end{itemize}

  \item Method 3 (fastest)
  \begin{itemize}
    \item Define a canonical order of subgraphs and explore them in that order.
    \item e.g. graphs in same equivalence class, if they have the same canonical spanning tree
    \item Does not need isomorphism tests
  \end{itemize}
\end{itemize}

\textbf{Conclusion}
\begin{itemize}
  \item Lots of sophisticated algorithms for mining frequent graph patterns: MoFa, gSpan, FFSM, Gaston, ..
  \item But the number of frequent patterns is exponential
  \item This implies three related problems:
  \begin{itemize}
    \item very high runtimes
    \item resulting sets of patterns hard to interpret
    \item minimum support threshold hard to set
  \end{itemize}
\end{itemize}

\textbf{Research Directions}
\begin{itemize}
  \item Mine only closed or maximal frequent graphs
  \begin{itemize}
    \item i.e. frequent graphs so that no supergraph has the same (or has at least $\theta$) support.
  \end{itemize}

  \item Summarize graph patterns
  \begin{itemize}
    \item find the top k most representative graphs
  \end{itemize}

  \item Constraint-based graph pattern mining
  \begin{itemize}
    \item Find only patterns that satisfy certain conditions on their size, density and diameter. 
  \end{itemize}
\end{itemize}

\subsubsection{Dense Graph Mining}
\begin{itemize}
  \item Assumption: the denser a graph, the more interesting
  \item Find dense subgraphs in a large graph
  \item Density of graph $G$: $density(G) = \frac{2|E|}{|V|(|V|-1)}$
  \item Want to find all subgraphs with density at least $\alpha$
\end{itemize}

\textbf{Weak Anti-Monotonicity Property}
\begin{itemize}
  \item If a graph of size k is dense, (at least) one of its subgraphs of size k-1 is dense.
  \item Thus cannot prune all candidate patterns that have a subgraph which is not dense.
  \item But can still enumerate patterns in a level-wise manner, extending only dense patterns by another node.
\end{itemize}

\textbf{Quasi-Cliques}
\begin{itemize}
  \item Graph G is $\gamma$-quasi-clique if every node $v \in G$ has at least $\gamma(|V|-1)$ edges
  \item For $\gamma \le 1$, the $\gamma$-quasi-clique property is not anti-monotone, not even weakly anti-monotone
\end{itemize}

\textbf{Mining Quasi-Cliques}
\begin{itemize}
  \item Enumerate all subgraphs
  \item Prune based on maximum diameter of $\gamma$-quasi-clique $G$
\end{itemize}

\subsubsection{Mining Cohesive Patterns}
\begin{itemize}
  \item Cohesive pattern: subgraph $G'$ satisfying three conditions:
  \begin{itemize}
    \item subspace $homogeneity$, i.e. attribute values are within a range of at most $\omega$ in at least $\delta$ dimensions
    \item $density$, i.e. has at least $\alpha$ of all possible edges
    \item $connectedness$, i.e. each pair of nodes has a connecting path in $G'$
  \end{itemize}

  \item Task: Find all maximal cohesive patterns
\end{itemize}

\textbf{Algorithm}
\begin{itemize}
  \item Cohesive Pattern Mining problem is NP-hard decision version reduceable from Max-Clique problem.
  \item An anti-monotone constraint: if for each network $G$ of size $n$ that satisfies the constraint, all induced subnetworks $G'$ of $G$ of size $n-1$ satisfy the constraint.
  \item Can prune all candidate networks that have a subnetwork not satisfying the constraint.
\end{itemize}

\subsection{Graph classification}

\textbf{Introduction}
\begin{itemize}
  \item Given two (or more) collections of labelled graphs, one for each of the relevant classes.
  \item E.g. collections of program flow graphs to distinguish faulty runs from correct ones
\end{itemize}

\subsubsection{Feature-based Graph Classification}
\begin{itemize}
  \item Define set of graph features
  \begin{itemize}
    \item global features such as diameter, degree distribution
    \item local features such as occurence of certin subgraphs 
  \end{itemize}

  \item Choice of relevant subgraphs
  \begin{itemize}
    \item based on domain knowledge, e.g. domain expert
    \item based on frequency, e.g. pattern mining algorithm
  \end{itemize}
\end{itemize}

\subsubsection{Kernel-based Graph Classification}
\begin{itemize}
  \item Kernel-based approach
  \begin{itemize}
    \item Map two graphs x and $x'$ into feature space via function $\Phi$
    \item Compute similarity (inner product) in feature space $$<\Phi(x), \Phi(x')>$$
    \item Kernel $k$ avoids actual computation of feature vectors $$k(x, x') = <\Phi(x), \Phi(x')>$$
  \end{itemize}

  \item Grpah kernels should capture relevant graph features and be efficient to compute
  \item Employ SVM or other kernel-based classifier
\end{itemize}


\subsection{Graph Clustering}
\textbf{Introduction}
\begin{itemize}
  \item Group nodes into clusters such that nodes within a cluster have similar relationships (edges) while nodes in different clusters have dissimilar relationships.
  \item Compared to graph classification: unsupervised
  \item Compared to graph pattern mining: global patterns, typically every node belongs to exactly one cluster
\end{itemize}

\subsubsection{Hierarchical Clustering}
\textbf{Divisive Hierarchical Clustering}
\begin{itemize}
  \item For every edge, compute its betweenness.
  \item Remove the edge with the highest betweenness, then recompute the edge betweenness
  \item Repeat these two steps until no more edge exists or until specified number of cluster produced
  \item Runtime $O(m^2n)$ where $m = |E|$ and $n = |V|$
  \item The method produces meaningful communities, but does not scale to large networks
  \item Divisive hierarchical algorithm always produces a clustering, whether there is some natural cluster structure or not.
\end{itemize}

\textbf{Agglomerative Hierarchical Clustering}
\begin{itemize}
  \item Define the modularity of a partitioning to measure its meaningfulness (deviation from randomness).
  \item $e_{ij}$: percentage of edges between partitions (clusters) i and j $$a_i = \sum_j {e_{ij}}$$
  \item Modualrity $$Q = \sum_i (e_{ii} - a_i^2)$$
  \item Start with singleton clusters.
  \item In each step, perform the merge of two clusters that leads to the largest increase of the modularity.
  \item Terminate when no more merges improve modularity or when specified number of clusters reached.
  \item Need to consider only connected pairs of clusters.
  \item Runtime $O((m+n) n)$ where $m = |E|$ and $n = |V|$
  \item Scales much better than divisive algorithm, clustering quality is quite comparable.
\end{itemize}

\subsubsection{Graph Cuts}
\begin{itemize}
  \item Graph cut: set of edges whose removal partitions the set of vertices V into two (disconnected) sets S and T.
  \item Cost of a cut: the sum of the weights of the cut edges.
  \item Edge weights can be derived from node attributes, e.g. similarity of attributes (attribute vectors).
  \item Minimum cut is a cut with minimum cost.
  \item Minimum cut tends to cut off very small, isolated components.
  \item Normalized cut $$\frac{cut(A, B)}{assoc(A, V)} + \frac{cut(A, B)}{assoc(B, V)}$$
  where $assoc(A, V)$ =  sum of weights of all edges in V that touch A
  \item Minimum normalized cut problem is NP-hard
  \item But approximation can be computed by solving generalized eigenvalue problem.
\end{itemize}

\subsubsection{Block Models}
\begin{itemize}
  \item Actors in a social network are structurally equivalent if they have identical relational ties to and from all the actors in a network.
  \item Partition V into subsets of nodes that have the same relationships i.e. edges to the same subset of $V$
  \item Graph represented as sociomatrix
  \item Partitions are called blocks
\end{itemize}

\textbf{CONCOR Algorithm}
\begin{itemize}
  \item repeated calculations of correleations between rows (or columns) will eventualy result in a correlation matrix consisting of only +1 and -1
  
  \item Algorithm
  \begin{itemize}
    \item calculate correlation matrix $C_1$ from sociomatrix
    \item calculate correlation matrix $C_2$ from $C_1$
    \item iterate until the entries are either +1 or -1
  \end{itemize}
\end{itemize}

\textbf{Stochastic Block Models}
\begin{itemize}
  \item Requirement of structural equivalence often too strict.
  \item Relax to stochastic equivalence:
  \begin{itemize}
    \item Two actors are stochastically equivalent if the actors are exchangeable with respect to the probability distribution.
  \end{itemize}
\end{itemize}

\textbf{Generative Model}
\begin{itemize}
  \item Assign nodes to clusters $$z| \gamma \sim CPR(\gamma)$$
  \item Determine link (edge) probability between clusters $$\eta_{ab} | \alpha, \beta \sim Beta(\alpha, \beta)$$
  \item Determine edges between nodes $$R_{ij} | z, \eta \sim Bernoulli(\eta_{z_i}{z_j})$$
  \item Assumption: edges conditionally independent given cluster assignments
  \item Prior $P(z)$ assigns a probability to all possible partitions of the nodes
  \item Find $z$ that maximizes $P(z|R)$
  \begin{itemize}
    \item $P(z|R) \propto P(R|z)P(z)$
    \item $P(R|z) = \prod_{ab} \frac{B(m_{ab} + \alpha, \bar m_{ab} + \beta)}{B(\alpha, \beta)}$
    \item where $m_{ab}$ is the number of edges between clusters $a$ and $b$ and $\bar m_{ab}$ is the number of missing edges betwwen clusters $a$ and $b$ and B(..., ...) is the Beta function.
  \end{itemize}
  \item Sample from the posterior P(z|R) using Markov Chain Monte Carlo
  
  \item Possible moves:
  \begin{itemize}
    \item move a node from one cluster to another
    \item split a cluster
    \item merge two clusters
  \end{itemize}

  \item At the end, $\eta_{ab}$ can be recovered
\end{itemize}

\subsection{Graph Evolution}
\subsubsection{Generative Models}
\begin{itemize}
  \item Erdos Renyi Model
  \begin{itemize}
    \item connect each pair of nodes with probability $p$
    \item Lots of theory, but does not produce power law degree distribution.
  \end{itemize}

  \item Preferential Attachment Model (directed graph)
  \begin{itemize}
    \item Add a new node, create m out-links to existing nodes.
    \item Probability of linking an existing node is proportional to its degree.
    \item Produces power law in-degree distribution but all nodes have the same out-degree.
  \end{itemize}

  \item Copy Model
  \begin{itemize}
    \item Add a node and choose k, the number of edges to add.
    \item With probability $\beta$, select $k$ random vertices and link to them.
    \item With probability $1-\beta$, edges are copied from a randomly chosen node.
    \item Generates power law degree distributions with exponent $1/(1- \beta)$ (Generate communities).
  \end{itemize}
\end{itemize}

\subsubsection{Diffusion Models}
\textbf{Introduction}
\begin{itemize}
  \item Each edge $(u,v)$ has probability $p_{uv}$ or weight $w_{uv}$
  \item Initially, some nodes are active (e.g. a, d, e, g, i)
  \item Question: which nodes will be active at some later time?
\end{itemize}

\textbf{Model}
\begin{itemize}
  \item Linear Threshold Model
  \begin{itemize}
    \item Each node has a threshold $t$
    \item Node $u$ is activated when $\sum_{v \in active(u)} w_{uv} > t$, where $active(u)$ are the active neighbors of $u$
    \item Deterministic activation
    \item Discrete time: sequence of time stamps t1,t2,t3,...
    \item At every time stamp $t_i$ , test each node whether it becomes active based on the activity status of the nodes at time $t_{i-1}$.
  \end{itemize}

  \item Independent Contagion Model
  \begin{itemize}
    \item Discrete time.
    \item When node $u$ becomes active, it activates each of its neighbors $v$ with probability $p_{uv}$ .
    \item A node has only one chance to influence its neighbors.
    \item Probabilistic activation.
  \end{itemize}
\end{itemize}

\textbf{Application}
\begin{itemize}
  \item Viral Marketing
  \item Influence Maximization
  
  \item Role of Communities
  \begin{itemize}
    \item Consider connectedness of friends.
    \item E.g. x and y have both three friends in the community
    \item Who is more likely to join the community?
    \begin{itemize}
      \item Information argument, unconnected friends give independent support.
      \item Social capital argument, safety / trust advantage in having friends who know each other.
      \item In LiveJournal, community joining probability increases with more connections among friends in community.
    \end{itemize}

  \end{itemize}

\end{itemize}

\end{document}